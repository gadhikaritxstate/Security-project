{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALL labels Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"------------------\"\n",
    "with open(\"./data/features_with_all_labels.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "features_dict = {}\n",
    "\n",
    "for line in lines[1:]:\n",
    "    line = line.strip()\n",
    "    splited_lines = line.split(delimiter)\n",
    "\n",
    "    features_dict[splited_lines[0]]=splited_lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/final_data_all_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Label\", axis=1)\n",
    "y = df[\"Label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gauravadhikari/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 5, 'lgbm__n_estimators': 50}\n",
      "Best Accuracy: 0.9890000000000001\n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('lgbm', lgb.LGBMClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'lgbm__n_estimators': [50, 100, 200],\n",
    "    'lgbm__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'lgbm__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "lgb_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gauravadhikari/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.6016666666666668\n",
      "Test Accuracy: 0.622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('adaboost', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'adaboost__n_estimators': [50, 100, 200],\n",
    "    'adaboost__learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "ada_classifier = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logreg__C': 100, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.8876666666666667\n",
      "Test Accuracy: 0.883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'logreg__penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "logistic_classifier = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.7416666666666666\n",
      "Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'nb__alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "naivebayes_classifier = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 7, 'xgb__n_estimators': 50}\n",
      "Best Accuracy: 0.9896874999999999\n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_iris  # Replace with your actual dataset\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with XGBoost classifier\n",
    "pipeline = Pipeline([\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [50, 100, 200],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "xgb_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 0.98875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "base_models = [\n",
    "    ('xgboost', xgb_classifier),\n",
    "    ('lightgbm', lgb_classifier),\n",
    "    ('adaboost', ada_classifier),\n",
    "    ('logistic', logistic_classifier),\n",
    "    ('naive_bayes', naivebayes_classifier)\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['variance_threshold', 'lasso', 'random_forest_feature_importance', 'recursive_feature_elimination', 'permutation_importance'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_threshold = df[[x for x in features_dict['variance_threshold'].split(',')]]\n",
    "df_lasso = df[[x for x in features_dict['lasso'].split(',')]]\n",
    "df_random_forest_feature_importance = df[[x for x in features_dict['random_forest_feature_importance'].split(',')]]\n",
    "df_permutation_importance = df[[x for x in features_dict['permutation_importance'].split(',')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.121764e-01</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>5.393023e-04</td>\n",
       "      <td>0.015026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.017604</td>\n",
       "      <td>0.497937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.716807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716807</td>\n",
       "      <td>0.716807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.100000e-06</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.952333e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3.581395e-06</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.452895e-01</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.381395e-05</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.023197</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.448739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448739</td>\n",
       "      <td>0.448739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.053253e-01</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>5.398605e-04</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.753095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.305042</td>\n",
       "      <td>0.586006</td>\n",
       "      <td>0.543697</td>\n",
       "      <td>0.065990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>1.128042e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>6.651163e-06</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>4.416667e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.790698e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>4.665850e-03</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5.398605e-04</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.494756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>7.134503e-01</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>5.393023e-04</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.017216</td>\n",
       "      <td>0.746905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.710924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710924</td>\n",
       "      <td>0.710924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>4.788605e-02</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0      7.121764e-01           0.001010                0.000607   \n",
       "1      1.100000e-06           0.000144                0.000000   \n",
       "2      1.952333e-04           0.000000                0.000101   \n",
       "3      4.452895e-01           0.000144                0.000202   \n",
       "4      6.053253e-01           0.001010                0.000506   \n",
       "...             ...                ...                     ...   \n",
       "3995   1.128042e-03           0.000000                0.000101   \n",
       "3996   4.416667e-07           0.000000                0.000101   \n",
       "3997   4.665850e-03           0.000289                0.000607   \n",
       "3998   7.134503e-01           0.000866                0.000709   \n",
       "3999   4.788605e-02           0.000289                0.000101   \n",
       "\n",
       "      Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                        0.000122                 5.393023e-04   \n",
       "1                        0.000013                 0.000000e+00   \n",
       "2                        0.000016                 3.581395e-06   \n",
       "3                        0.000036                 1.381395e-05   \n",
       "4                        0.000020                 5.398605e-04   \n",
       "...                           ...                          ...   \n",
       "3995                     0.000016                 6.651163e-06   \n",
       "3996                     0.000000                 2.790698e-07   \n",
       "3997                     0.000009                 5.398605e-04   \n",
       "3998                     0.000119                 5.393023e-04   \n",
       "3999                     0.000000                 0.000000e+00   \n",
       "\n",
       "      Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                  0.015026               0.000000                0.007385   \n",
       "1                  0.001584               0.000000                0.003114   \n",
       "2                  0.001926               0.022693                0.007575   \n",
       "3                  0.002483               0.023197                0.008753   \n",
       "4                  0.000856               0.000000                0.001178   \n",
       "...                     ...                    ...                     ...   \n",
       "3995               0.001926               0.022693                0.007575   \n",
       "3996               0.000000               0.000000                0.000000   \n",
       "3997               0.000856               0.000000                0.001459   \n",
       "3998               0.013870               0.000000                0.008224   \n",
       "3999               0.000000               0.000000                0.000000   \n",
       "\n",
       "      Fwd Packet Length Std  Bwd Packet Length Max  ...  act_data_pkt_fwd  \\\n",
       "0                  0.017604               0.497937  ...          0.000167   \n",
       "1                  0.003711               0.000000  ...          0.000000   \n",
       "2                  0.000000               0.006620  ...          0.000000   \n",
       "3                  0.001204               0.015990  ...          0.000167   \n",
       "4                  0.000802               0.753095  ...          0.001001   \n",
       "...                     ...                    ...  ...               ...   \n",
       "3995               0.000000               0.012294  ...          0.000000   \n",
       "3996               0.000000               0.000516  ...          0.000000   \n",
       "3997               0.001456               0.494756  ...          0.000334   \n",
       "3998               0.017216               0.746905  ...          0.000501   \n",
       "3999               0.000000               0.000000  ...          0.000000   \n",
       "\n",
       "      min_seg_size_forward  Active Mean  Active Std  Active Max  Active Min  \\\n",
       "0                 0.533333     0.000020         0.0    0.000020    0.000020   \n",
       "1                 0.533333     0.000000         0.0    0.000000    0.000000   \n",
       "2                 0.533333     0.000000         0.0    0.000000    0.000000   \n",
       "3                 0.533333     0.000307         0.0    0.000307    0.000307   \n",
       "4                 0.333333     0.000010         0.0    0.000010    0.000010   \n",
       "...                    ...          ...         ...         ...         ...   \n",
       "3995              0.533333     0.000000         0.0    0.000000    0.000000   \n",
       "3996              0.666667     0.000000         0.0    0.000000    0.000000   \n",
       "3997              0.333333     0.000000         0.0    0.000000    0.000000   \n",
       "3998              0.333333     0.000109         0.0    0.000109    0.000109   \n",
       "3999              0.533333     0.000000         0.0    0.000000    0.000000   \n",
       "\n",
       "      Idle Mean  Idle Std  Idle Max  Idle Min  \n",
       "0      0.716807  0.000000  0.716807  0.716807  \n",
       "1      0.000000  0.000000  0.000000  0.000000  \n",
       "2      0.000000  0.000000  0.000000  0.000000  \n",
       "3      0.448739  0.000000  0.448739  0.448739  \n",
       "4      0.305042  0.586006  0.543697  0.065990  \n",
       "...         ...       ...       ...       ...  \n",
       "3995   0.000000  0.000000  0.000000  0.000000  \n",
       "3996   0.000000  0.000000  0.000000  0.000000  \n",
       "3997   0.000000  0.000000  0.000000  0.000000  \n",
       "3998   0.710924  0.000000  0.710924  0.710924  \n",
       "3999   0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[4000 rows x 65 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_variance_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label column to every df\n",
    "\n",
    "df_features_dict={\n",
    "    \"df_variance_threshold\":df_variance_threshold,\n",
    "    \"df_lasso\":df_lasso,\n",
    "    \"df_random_forest_feature_importance\":df_random_forest_feature_importance,\n",
    "    \"df_permutation_importance\":df_permutation_importance,\n",
    "}\n",
    "\n",
    "for df_feature in df_features_dict.keys():\n",
    "    df_features_dict[df_feature]['Label'] = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running LGB classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # LGB classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('lgbm', lgb.LGBMClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'lgbm__n_estimators': [50, 100, 200],\n",
    "        'lgbm__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'lgbm__max_depth': [3, 5, 7]\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    lgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Adaboost classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Adaboost\n",
    "    pipeline = Pipeline([\n",
    "        ('adaboost', AdaBoostClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'adaboost__n_estimators': [50, 100, 200],\n",
    "        'adaboost__learning_rate': [0.01, 0.1, 0.2],\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    ada_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "    # Logistic\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Logistic classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('logreg', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'logreg__C': [0.001, 0.01, 0.1],\n",
    "        'logreg__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    logistic_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Naive bayes classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #Naive bayes\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('nb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'nb__alpha': [0.1, 0.5, 1.0]\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    naivebayes_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running XGB classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('xgb', xgb.XGBClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'xgb__n_estimators': [50, 100],\n",
    "        'xgb__learning_rate': [0.01, 0.1],\n",
    "        'xgb__max_depth': [3, 5]\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Stacking based classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Stacking\n",
    "    base_models = [\n",
    "        ('xgboost', xgb_classifier),\n",
    "        ('lightgbm', lgb_classifier),\n",
    "        ('adaboost', ada_classifier),\n",
    "        ('logistic', logistic_classifier),\n",
    "        ('naive_bayes', naivebayes_classifier)\n",
    "    ]\n",
    "    meta_model = LogisticRegression()\n",
    "    stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "    stacking_classifier.fit(X_train, y_train)\n",
    "    y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "    stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "    print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9896875000000002\n",
      "Test Accuracy: 0.98125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.60125\n",
      "Test Accuracy: 0.62875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.776875\n",
      "Test Accuracy: 0.825\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.74\n",
      "Test Accuracy: 0.76\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9890625\n",
      "Test Accuracy: 0.99125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.9825\n"
     ]
    }
   ],
   "source": [
    "X=df_variance_threshold.drop('Label',axis=1)\n",
    "y=df_variance_threshold['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp_df, y, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9893750000000001\n",
      "Test Accuracy: 0.98125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.60125\n",
      "Test Accuracy: 0.62875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.6496875000000001\n",
      "Test Accuracy: 0.6525\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.566875\n",
      "Test Accuracy: 0.5975\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9890625\n",
      "Test Accuracy: 0.9875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.9875\n"
     ]
    }
   ],
   "source": [
    "X=df_permutation_importance.drop('Label',axis=1)\n",
    "y=df_permutation_importance['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp_df, y, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9878125000000001\n",
      "Test Accuracy: 0.9775\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.6881250000000001\n",
      "Test Accuracy: 0.7125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.001, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.5878124999999998\n",
      "Test Accuracy: 0.6125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.5821875000000001\n",
      "Test Accuracy: 0.60875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9868750000000001\n",
      "Test Accuracy: 0.98625\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.9825\n"
     ]
    }
   ],
   "source": [
    "X=df_random_forest_feature_importance.drop('Label',axis=1)\n",
    "y=df_random_forest_feature_importance['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp_df, y, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.01, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.8521875\n",
      "Test Accuracy: 0.855\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.6915625000000001\n",
      "Test Accuracy: 0.7175\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.60375\n",
      "Test Accuracy: 0.60625\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.54\n",
      "Test Accuracy: 0.56875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.8543749999999999\n",
      "Test Accuracy: 0.86\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.86125\n"
     ]
    }
   ],
   "source": [
    "X=df_lasso.drop('Label',axis=1)\n",
    "y=df_lasso['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(temp_df, y, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "security",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
