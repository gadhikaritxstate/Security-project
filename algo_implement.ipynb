{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALL labels Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_feature_dict = {}\n",
    "delimiter = \"------------------\"\n",
    "with open(\"./data/features_with_all_labels.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "features_dict = {}\n",
    "\n",
    "for line in lines[1:]:\n",
    "    line = line.strip()\n",
    "    splited_lines = line.split(delimiter)\n",
    "    features_dict[splited_lines[0]]=splited_lines[1]\n",
    "    \n",
    "subset_feature_dict['lasso']=features_dict['lasso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso': 'Fwd IAT Max,PSH Flag Count,ACK Flag Count'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/final_data_all_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Label\", axis=1)\n",
    "y = df[\"Label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "all_X_test, all_y_test= X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 5, 'lgbm__n_estimators': 50}\n",
      "Best Accuracy: 0.9890000000000001\n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lgbm', lgb.LGBMClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'lgbm__n_estimators': [50, 100, 200],\n",
    "    'lgbm__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'lgbm__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "lgb_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.6016666666666668\n",
      "Test Accuracy: 0.622\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('adaboost', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'adaboost__n_estimators': [50, 100, 200],\n",
    "    'adaboost__learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "ada_classifier = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logreg__C': 100, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.8876666666666667\n",
      "Test Accuracy: 0.883\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'logreg__penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "logistic_classifier = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.7416666666666666\n",
      "Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'nb__alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "naivebayes_classifier = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with XGBoost classifier\n",
    "pipeline = Pipeline([\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [50, 100],\n",
    "    # 'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    # 'xgb__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "xgb_classifier = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 0.991\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    # ('xgboost', xgb_classifier),\n",
    "    ('lightgbm', lgb_classifier),\n",
    "    ('adaboost', ada_classifier),\n",
    "    ('logistic', logistic_classifier),\n",
    "    ('naive_bayes', naivebayes_classifier)\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))\n",
    "\n",
    "all_stacking_classifier=stacking_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variance_threshold': 'Flow Duration,Total Fwd Packets,Total Backward Packets,Total Length of Fwd Packets,Total Length of Bwd Packets,Fwd Packet Length Max,Fwd Packet Length Min,Fwd Packet Length Mean,Fwd Packet Length Std,Bwd Packet Length Max,Bwd Packet Length Min,Bwd Packet Length Mean,Bwd Packet Length Std,Flow Bytes/s,Flow Packets/s,Flow IAT Mean,Flow IAT Std,Flow IAT Max,Flow IAT Min,Fwd IAT Total,Fwd IAT Mean,Fwd IAT Std,Fwd IAT Max,Fwd IAT Min,Bwd IAT Total,Bwd IAT Mean,Bwd IAT Std,Bwd IAT Max,Bwd IAT Min,Fwd PSH Flags,Fwd Header Length,Bwd Header Length,Fwd Packets/s,Bwd Packets/s,Min Packet Length,Max Packet Length,Packet Length Mean,Packet Length Std,Packet Length Variance,FIN Flag Count,SYN Flag Count,PSH Flag Count,ACK Flag Count,URG Flag Count,Down/Up Ratio,Average Packet Size,Avg Fwd Segment Size,Avg Bwd Segment Size,Fwd Header Length.1,Subflow Fwd Packets,Subflow Fwd Bytes,Subflow Bwd Packets,Subflow Bwd Bytes,Init_Win_bytes_forward,Init_Win_bytes_backward,act_data_pkt_fwd,min_seg_size_forward,Active Mean,Active Std,Active Max,Active Min,Idle Mean,Idle Std,Idle Max,Idle Min',\n",
       " 'lasso': 'Fwd IAT Max,PSH Flag Count,ACK Flag Count',\n",
       " 'random_forest_feature_importance': 'Packet Length Std,Init_Win_bytes_forward,Packet Length Mean,Bwd Packet Length Mean,Avg Bwd Segment Size,Bwd Packet Length Max,Fwd Header Length.1,Bwd Packet Length Std,Average Packet Size,Init_Win_bytes_backward,Fwd Header Length,Packet Length Variance,Bwd Header Length,Bwd Packets/s,Fwd Packet Length Max,Total Length of Bwd Packets,Total Length of Fwd Packets,Max Packet Length',\n",
       " 'recursive_feature_elimination': 'Total Length of Fwd Packets,Fwd Packet Length Max,Bwd Packet Length Max,Bwd Packet Length Min,Bwd Packet Length Mean,Bwd Packet Length Std,Fwd Header Length,Bwd Packets/s,Max Packet Length,Packet Length Mean,Packet Length Std,Packet Length Variance,Average Packet Size,Avg Bwd Segment Size,Fwd Header Length.1,Subflow Fwd Bytes,Init_Win_bytes_forward,Init_Win_bytes_backward',\n",
       " 'permutation_importance': 'Init_Win_bytes_forward,Fwd IAT Min,Init_Win_bytes_backward,Total Backward Packets,Subflow Fwd Packets,Bwd IAT Min,act_data_pkt_fwd,Bwd Packet Length Std,Total Fwd Packets,Fwd IAT Max,Subflow Bwd Packets,Fwd Packet Length Std,Fwd IAT Total,Max Packet Length,Flow IAT Min,min_seg_size_forward,Idle Min,Bwd Avg Packets/Bulk'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_threshold = df[[x for x in features_dict['variance_threshold'].split(',')]]\n",
    "df_lasso = df[[x for x in features_dict['lasso'].split(',')]]\n",
    "df_random_forest_feature_importance = df[[x for x in features_dict['random_forest_feature_importance'].split(',')]]\n",
    "df_permutation_importance = df[[x for x in features_dict['permutation_importance'].split(',')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label column to every df\n",
    "\n",
    "df_features_dict={\n",
    "    \"df_variance_threshold\":df_variance_threshold,\n",
    "    \"df_lasso\":df_lasso,\n",
    "    \"df_random_forest_feature_importance\":df_random_forest_feature_importance,\n",
    "    \"df_permutation_importance\":df_permutation_importance,\n",
    "}\n",
    "\n",
    "for df_feature in df_features_dict.keys():\n",
    "    df_features_dict[df_feature]['Label'] = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running LGB classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # LGB classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('lgbm', lgb.LGBMClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'lgbm__n_estimators': [50, 100, 200],\n",
    "        'lgbm__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'lgbm__max_depth': [3, 5, 7]\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    lgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Adaboost classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Adaboost\n",
    "    pipeline = Pipeline([\n",
    "        ('adaboost', AdaBoostClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'adaboost__n_estimators': [50, 100, 200],\n",
    "        'adaboost__learning_rate': [0.01, 0.1, 0.2],\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    ada_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "    # Logistic\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Logistic classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('logreg', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'logreg__C': [0.001, 0.01, 0.1],\n",
    "        'logreg__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    logistic_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Naive bayes classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #Naive bayes\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('nb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'nb__alpha': [0.1, 0.5, 1.0]\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    naivebayes_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running XGB classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('xgb', xgb.XGBClassifier())\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'xgb__n_estimators': [50, 100],\n",
    "        'xgb__learning_rate': [0.01, 0.1],\n",
    "        'xgb__max_depth': [3, 5]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Stacking based classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Stacking\n",
    "    base_models = [\n",
    "        ('xgboost', xgb_classifier),\n",
    "        ('lightgbm', lgb_classifier),\n",
    "        ('adaboost', ada_classifier),\n",
    "        ('logistic', logistic_classifier),\n",
    "        ('naive_bayes', naivebayes_classifier)\n",
    "    ]\n",
    "    meta_model = LogisticRegression()\n",
    "    stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "    stacking_classifier.fit(X_train, y_train)\n",
    "    y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "    stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "    print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9896875000000002\n",
      "Test Accuracy: 0.98125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.60125\n",
      "Test Accuracy: 0.62875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.776875\n",
      "Test Accuracy: 0.825\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.74\n",
      "Test Accuracy: 0.76\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9890625\n",
      "Test Accuracy: 0.99125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.9825\n"
     ]
    }
   ],
   "source": [
    "X=df_variance_threshold.drop('Label',axis=1)\n",
    "y=df_variance_threshold['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9893750000000001\n",
      "Test Accuracy: 0.98125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.60125\n",
      "Test Accuracy: 0.62875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.6496875000000001\n",
      "Test Accuracy: 0.6525\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.566875\n",
      "Test Accuracy: 0.5975\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9890625\n",
      "Test Accuracy: 0.9875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.9875\n"
     ]
    }
   ],
   "source": [
    "X=df_permutation_importance.drop('Label',axis=1)\n",
    "y=df_permutation_importance['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_random_forest_feature_importance.drop('Label',axis=1)\n",
    "y=df_random_forest_feature_importance['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on multiclass labels\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.01, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.8521875\n",
      "Test Accuracy: 0.855\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.6915625000000001\n",
      "Test Accuracy: 0.7175\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.60375\n",
      "Test Accuracy: 0.60625\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.54\n",
      "Test Accuracy: 0.56875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.8543749999999999\n",
      "Test Accuracy: 0.86\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.86125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Model running on multiclass labels\")\n",
    "\n",
    "X=df_lasso.drop('Label',axis=1)\n",
    "y=df_lasso['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TWO labels Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/final_data_two_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"------------------\"\n",
    "with open(\"./data/features_with_two_labels.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "features_dict = {}\n",
    "for line in lines[1:]:\n",
    "    line = line.strip()\n",
    "    splited_lines = line.split(delimiter)\n",
    "    features_dict[splited_lines[0]]=splited_lines[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_threshold_two = df[[x for x in features_dict['variance_threshold'].split(',')]]\n",
    "df_random_forest_feature_importance_two = df[[x for x in features_dict['random_forest_feature_importance'].split(',')]]\n",
    "df_recursive_feature_elimination_two = df[[x for x in features_dict['recursive_feature_elimination'].split(',')]]\n",
    "df_permutation_importance_two = df[[x for x in features_dict['permutation_importance'].split(',')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_dict={\n",
    "    \"df_variance_threshold\":df_variance_threshold_two,\n",
    "    \"df_random_forest_feature_importance\":df_random_forest_feature_importance_two,\n",
    "    \"df_permutation_importance\":df_permutation_importance_two,\n",
    "    \"recursive_feature_elimination\":df_recursive_feature_elimination_two\n",
    "}\n",
    "\n",
    "df_variance_threshold_two['Label'] = df['Label']\n",
    "df_random_forest_feature_importance_two['Label'] = df['Label']\n",
    "df_recursive_feature_elimination_two['Label'] = df['Label']\n",
    "df_permutation_importance_two['Label'] = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Init_Win_bytes_forward', 'Init_Win_bytes_backward',\n",
       "       'min_seg_size_forward', 'Flow IAT Min', 'Bwd Packet Length Std',\n",
       "       'URG Flag Count', 'Fwd IAT Mean', 'Fwd IAT Total',\n",
       "       'Total Backward Packets', 'Bwd IAT Max', 'Bwd IAT Mean',\n",
       "       'Bwd Packet Length Max', 'Fwd Header Length.1', 'Min Packet Length',\n",
       "       'Subflow Bwd Packets', 'Bwd IAT Min', 'Active Std', 'Idle Std',\n",
       "       'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_permutation_importance_two.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.2, 'lgbm__max_depth': 5, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9886666666666667\n",
      "Test Accuracy: 0.985\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9416666666666668\n",
      "Test Accuracy: 0.939\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.8170000000000002\n",
      "Test Accuracy: 0.824\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 1.0}\n",
      "Best Accuracy: 0.44700000000000006\n",
      "Test Accuracy: 0.425\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9869999999999999\n",
      "Test Accuracy: 0.985\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.985\n"
     ]
    }
   ],
   "source": [
    "X=df_variance_threshold_two.drop('Label',axis=1)\n",
    "y=df_variance_threshold_two['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.2, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9886666666666667\n",
      "Test Accuracy: 0.989\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9626666666666667\n",
      "Test Accuracy: 0.958\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.7433333333333334\n",
      "Test Accuracy: 0.809\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.711\n",
      "Test Accuracy: 0.731\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.984\n",
      "Test Accuracy: 0.983\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.989\n"
     ]
    }
   ],
   "source": [
    "X=df_random_forest_feature_importance_two.drop('Label',axis=1)\n",
    "y=df_random_forest_feature_importance_two['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.2, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 100}\n",
      "Best Accuracy: 0.9880000000000001\n",
      "Test Accuracy: 0.987\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9629999999999999\n",
      "Test Accuracy: 0.957\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.63\n",
      "Test Accuracy: 0.647\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.5}\n",
      "Best Accuracy: 0.6486666666666666\n",
      "Test Accuracy: 0.649\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9856666666666666\n",
      "Test Accuracy: 0.985\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.987\n"
     ]
    }
   ],
   "source": [
    "X=df_recursive_feature_elimination_two.drop('Label',axis=1)\n",
    "y=df_recursive_feature_elimination_two['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.2, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9886666666666667\n",
      "Test Accuracy: 0.992\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9506666666666665\n",
      "Test Accuracy: 0.94\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.6699999999999999\n",
      "Test Accuracy: 0.63\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.5}\n",
      "Best Accuracy: 0.5896666666666667\n",
      "Test Accuracy: 0.626\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9853333333333334\n",
      "Test Accuracy: 0.982\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.991\n"
     ]
    }
   ],
   "source": [
    "X=df_permutation_importance_two.drop('Label',axis=1)\n",
    "y=df_permutation_importance_two['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Subset features for pca\n",
    "for key, item in features_dict.items():\n",
    "    if key=='lasso' or key=='variance_threshold':\n",
    "        continue\n",
    "    subset_feature_dict[key]=item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO separate into columns\n",
    "# print(\"Model running on two labels\")\n",
    "# X = df.drop(\"Label\", axis=1)\n",
    "# y = df[\"Label\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_models = [\n",
    "#     ('xgboost', xgb.XGBClassifier()),\n",
    "#     ('lightgbm', lgb.LGBMClassifier()),\n",
    "#     ('adaboost', AdaBoostClassifier()),\n",
    "#     ('logistic', LogisticRegression()),\n",
    "#     ('naive_bayes', MultinomialNB())\n",
    "# ]\n",
    "# meta_model = LogisticRegression()\n",
    "# stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "# stacking_classifier.fit(X_train, y_train)\n",
    "# y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "# stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "# print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso': 'Fwd IAT Max,PSH Flag Count,ACK Flag Count',\n",
       " 'random_forest_feature_importance': 'Init_Win_bytes_forward,Init_Win_bytes_backward,Fwd Packet Length Min,Fwd Packet Length Max,Bwd Packet Length Min,Bwd Packet Length Mean,Avg Bwd Segment Size,Min Packet Length,Packet Length Std,Avg Fwd Segment Size,Bwd Packet Length Max,Packet Length Mean,Average Packet Size,Total Length of Fwd Packets,Subflow Fwd Bytes,Fwd Header Length.1,Fwd Header Length,Packet Length Variance',\n",
       " 'recursive_feature_elimination': 'Total Length of Fwd Packets,Fwd Packet Length Max,Fwd Packet Length Min,Fwd Packet Length Mean,Bwd Packet Length Max,Bwd Packet Length Min,Bwd Packet Length Mean,Bwd Packet Length Std,Flow Packets/s,Fwd Header Length,Min Packet Length,Max Packet Length,Packet Length Mean,Packet Length Std,Packet Length Variance,Average Packet Size,Avg Fwd Segment Size,Avg Bwd Segment Size,Fwd Header Length.1,Subflow Fwd Packets,Subflow Fwd Bytes,Init_Win_bytes_forward,Init_Win_bytes_backward,act_data_pkt_fwd,min_seg_size_forward',\n",
       " 'permutation_importance': 'Init_Win_bytes_forward,Init_Win_bytes_backward,min_seg_size_forward,Flow IAT Min,Bwd Packet Length Std,URG Flag Count,Fwd IAT Mean,Fwd IAT Total,Total Backward Packets,Bwd IAT Max,Bwd IAT Mean,Bwd Packet Length Max,Fwd Header Length.1,Min Packet Length,Subflow Bwd Packets,Bwd IAT Min,Active Std,Idle Std'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats this\n",
    "# y_pred = stacking_classifier.predict(df.drop('Label',axis=1))\n",
    "# incorrect_twolabel_idx = (df['Label'] != y_pred)\n",
    "# incorrect_predicted_df = df[incorrect_twolabel_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fwd IAT Max', 'Init_Win_bytes_backward', 'Min Packet Length', 'Init_Win_bytes_forward', 'PSH Flag Count', 'Fwd Header Length.1', 'Bwd Packet Length Max', 'ACK Flag Count']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "imp1 = set([x for x in subset_feature_dict['random_forest_feature_importance'].split(',') if x ])\n",
    "imp2 = set([x for x in subset_feature_dict['recursive_feature_elimination'].split(',') if x ])\n",
    "imp3 = set([x for x in subset_feature_dict['permutation_importance'].split(',') if x ])\n",
    "imp4 = set([x for x in subset_feature_dict['lasso'].split(',') if x ])\n",
    "\n",
    "finalset = imp1.intersection(imp2).intersection(imp3)\n",
    "finalset=list(finalset.union(imp4))\n",
    "print(finalset)\n",
    "print(len(finalset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twolabel= pd.read_csv(\"./data/final_data_two_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.2, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 100}\n",
      "Best Accuracy: 0.9896666666666667\n",
      "Test Accuracy: 0.99\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9390000000000001\n",
      "Test Accuracy: 0.935\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.7836666666666667\n",
      "Test Accuracy: 0.808\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.6\n",
      "Test Accuracy: 0.624\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9843333333333334\n",
      "Test Accuracy: 0.984\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.988\n"
     ]
    }
   ],
   "source": [
    "# Training on the final set \n",
    "X=df_twolabel[finalset]\n",
    "y=df_twolabel['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 0.986\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('xgboost', xgb.XGBClassifier()),\n",
    "    ('lightgbm', lgb.LGBMClassifier()),\n",
    "    ('adaboost', AdaBoostClassifier()),\n",
    "    ('logistic', LogisticRegression()),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the label from stacking classifier and finding out the incorrectly classified labels\n",
    "y_predict = stacking_classifier.predict(X)\n",
    "incorrect_twolabel_idx = (y != y_predict)\n",
    "\n",
    "df_exclude_from_pca = X[incorrect_twolabel_idx]\n",
    "df_exclude_from_pca['Label']=y[incorrect_twolabel_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>Init_Win_bytes_backward</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Flow IAT Min</th>\n",
       "      <th>Bwd Packet Length Std</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>Fwd IAT Mean</th>\n",
       "      <th>Fwd IAT Total</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>Fwd Header Length.1</th>\n",
       "      <th>Min Packet Length</th>\n",
       "      <th>Subflow Bwd Packets</th>\n",
       "      <th>Bwd IAT Min</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.022049</td>\n",
       "      <td>0.017960</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>6.890756e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.022049</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>7.226891e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.445572</td>\n",
       "      <td>0.441910</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>7.310924e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024669</td>\n",
       "      <td>0.048927</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.508194</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.588235e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.966387e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>0.445572</td>\n",
       "      <td>0.647110</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>2.689076e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022919</td>\n",
       "      <td>0.045456</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.714286e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.368333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.537815e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.245378e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>0.445572</td>\n",
       "      <td>0.441910</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>5.462185e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.042004</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.521008e-08</td>\n",
       "      <td>0.248443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.354625</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>1.512605e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>0.022049</td>\n",
       "      <td>0.017960</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>5.714286e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>0.125015</td>\n",
       "      <td>0.017776</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.680672e-08</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>8.403361e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>0.445572</td>\n",
       "      <td>0.441910</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>3.865546e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.045610</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1.875714e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Init_Win_bytes_forward  Init_Win_bytes_backward  min_seg_size_forward  \\\n",
       "73                  0.022049                 0.017960              0.533333   \n",
       "314                 0.022049                 0.017929              0.533333   \n",
       "532                 0.445572                 0.441910              0.533333   \n",
       "817                 0.003723                 0.508194              0.533333   \n",
       "907                 0.021973                 0.000000              0.533333   \n",
       "923                 0.445572                 0.647110              0.533333   \n",
       "1128                0.003922                 0.000000              0.333333   \n",
       "1268                0.003754                 0.000000              0.533333   \n",
       "2131                0.000015                 0.000000              0.333333   \n",
       "2171                0.445572                 0.441910              0.533333   \n",
       "2413                1.000000                 0.000137              0.333333   \n",
       "2456                0.022049                 0.017960              0.533333   \n",
       "3455                0.125015                 0.017776              0.333333   \n",
       "3469                0.445572                 0.441910              0.533333   \n",
       "\n",
       "      Flow IAT Min  Bwd Packet Length Std  URG Flag Count  Fwd IAT Mean  \\\n",
       "73    6.890756e-07               0.000000             1.0      0.000000   \n",
       "314   7.226891e-07               0.000000             1.0      0.000000   \n",
       "532   7.310924e-07               0.000000             0.0      0.024669   \n",
       "817   1.588235e-06               0.000000             0.0      0.001191   \n",
       "907   2.966387e-06               0.000000             0.0      0.000003   \n",
       "923   2.689076e-07               0.000000             0.0      0.022919   \n",
       "1128  3.714286e-01               0.000000             0.0      0.371429   \n",
       "1268  1.537815e-06               0.000000             0.0      0.000002   \n",
       "2131  9.245378e-05               0.000000             0.0      0.000092   \n",
       "2171  5.462185e-07               0.000000             0.0      0.021178   \n",
       "2413  2.521008e-08               0.248443             0.0      0.000033   \n",
       "2456  5.714286e-07               0.000000             1.0      0.000000   \n",
       "3455  1.680672e-08               0.003454             0.0      0.000039   \n",
       "3469  3.865546e-07               0.000000             0.0      0.015331   \n",
       "\n",
       "      Fwd IAT Total  Total Backward Packets  Bwd IAT Max  Bwd IAT Mean  \\\n",
       "73         0.000000                0.000101     0.000000      0.000000   \n",
       "314        0.000000                0.000101     0.000000      0.000000   \n",
       "532        0.048927                0.000101     0.000000      0.000000   \n",
       "817        0.001181                0.000101     0.000000      0.000000   \n",
       "907        0.000003                0.000000     0.000000      0.000000   \n",
       "923        0.045456                0.000101     0.000000      0.000000   \n",
       "1128       0.368333                0.000000     0.000000      0.000000   \n",
       "1268       0.000002                0.000000     0.000000      0.000000   \n",
       "2131       0.000092                0.000000     0.000000      0.000000   \n",
       "2171       0.042004                0.000101     0.000000      0.000000   \n",
       "2413       0.000651                0.001114     0.016764      0.001742   \n",
       "2456       0.000000                0.000101     0.000000      0.000000   \n",
       "3455       0.000782                0.002835     0.000713      0.000029   \n",
       "3469       0.045610                0.000202     0.000188      0.000188   \n",
       "\n",
       "      Bwd Packet Length Max  Fwd Header Length.1  Min Packet Length  \\\n",
       "73                 0.000000             0.000209           0.000000   \n",
       "314                0.000000             0.000209           0.000000   \n",
       "532                0.000000             0.000680           0.000000   \n",
       "817                0.000000             0.000497           0.000000   \n",
       "907                0.000000             0.000418           0.000000   \n",
       "923                0.000000             0.000680           0.000000   \n",
       "1128               0.000000             0.000262           0.004525   \n",
       "1268               0.000000             0.000418           0.000000   \n",
       "2131               0.000000             0.000262           0.004525   \n",
       "2171               0.000000             0.000680           0.000000   \n",
       "2413               0.354625             0.002825           0.000000   \n",
       "2456               0.000000             0.000209           0.000000   \n",
       "3455               0.011004             0.002825           0.000000   \n",
       "3469               0.000000             0.000889           0.000000   \n",
       "\n",
       "      Subflow Bwd Packets   Bwd IAT Min  Active Std  Idle Std  Label  \n",
       "73               0.000101  0.000000e+00         0.0       0.0      0  \n",
       "314              0.000101  0.000000e+00         0.0       0.0      0  \n",
       "532              0.000101  0.000000e+00         0.0       0.0      1  \n",
       "817              0.000101  0.000000e+00         0.0       0.0      1  \n",
       "907              0.000000  0.000000e+00         0.0       0.0      0  \n",
       "923              0.000101  0.000000e+00         0.0       0.0      1  \n",
       "1128             0.000000  0.000000e+00         0.0       0.0      0  \n",
       "1268             0.000000  0.000000e+00         0.0       0.0      1  \n",
       "2131             0.000000  0.000000e+00         0.0       0.0      0  \n",
       "2171             0.000101  0.000000e+00         0.0       0.0      1  \n",
       "2413             0.001114  1.512605e-06         0.0       0.0      1  \n",
       "2456             0.000101  0.000000e+00         0.0       0.0      0  \n",
       "3455             0.002835  8.403361e-09         0.0       0.0      0  \n",
       "3469             0.000202  1.875714e-04         0.0       0.0      1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exclude_from_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WorkIng with PCA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.read_csv('./data/sample_pca_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 19)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train =  pca_df[~incorrect_twolabel_idx].drop('Label',axis=1),pca_df[~incorrect_twolabel_idx]['Label']\n",
    "X_test, y_test =  pca_df[incorrect_twolabel_idx].drop('Label',axis=1),pca_df[incorrect_twolabel_idx]['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3986, 18), (14, 18))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('xgboost', xgb.XGBClassifier()),\n",
    "    ('lightgbm', lgb.LGBMClassifier()),\n",
    "    ('adaboost', AdaBoostClassifier()),\n",
    "    ('logistic', LogisticRegression()),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "\n",
    "print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "security",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
