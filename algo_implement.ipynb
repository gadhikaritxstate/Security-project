{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALL labels Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_feature_dict = {}\n",
    "delimiter = \"------------------\"\n",
    "with open(\"./data/features_with_all_labels.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "features_dict = {}\n",
    "\n",
    "for line in lines[1:]:\n",
    "    line = line.strip()\n",
    "    splited_lines = line.split(delimiter)\n",
    "    features_dict[splited_lines[0]]=splited_lines[1]\n",
    "\n",
    "subset_feature_dict['lasso']=features_dict['lasso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso': 'Fwd IAT Max,PSH Flag Count,ACK Flag Count'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/final_data_all_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Label\", axis=1)\n",
    "y = df[\"Label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "all_X_test, all_y_test= X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 5, 'lgbm__n_estimators': 50}\n",
      "Best Accuracy: 0.9890000000000001\n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('lgbm', lgb.LGBMClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'lgbm__n_estimators': [50, 100, 200],\n",
    "    'lgbm__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'lgbm__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "lgb_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.6016666666666668\n",
      "Test Accuracy: 0.622\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('adaboost', AdaBoostClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'adaboost__n_estimators': [50, 100, 200],\n",
    "    'adaboost__learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "ada_classifier = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logreg__C': 100, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.8876666666666667\n",
      "Test Accuracy: 0.883\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'logreg__penalty': ['l1', 'l2'],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "logistic_classifier = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.7416666666666666\n",
      "Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'nb__alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "naivebayes_classifier = grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 7, 'xgb__n_estimators': 50}\n",
      "Best Accuracy: 0.9896874999999999\n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with XGBoost classifier\n",
    "pipeline = Pipeline([\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': [50, 100, 200],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = grid_search.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "xgb_classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 0.98875\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('xgboost', xgb_classifier),\n",
    "    ('lightgbm', lgb_classifier),\n",
    "    ('adaboost', ada_classifier),\n",
    "    ('logistic', logistic_classifier),\n",
    "    ('naive_bayes', naivebayes_classifier)\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))\n",
    "\n",
    "all_stacking_classifier=stacking_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['variance_threshold', 'lasso', 'random_forest_feature_importance', 'recursive_feature_elimination', 'permutation_importance'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_threshold = df[[x for x in features_dict['variance_threshold'].split(',')]]\n",
    "df_lasso = df[[x for x in features_dict['lasso'].split(',')]]\n",
    "df_random_forest_feature_importance = df[[x for x in features_dict['random_forest_feature_importance'].split(',')]]\n",
    "df_permutation_importance = df[[x for x in features_dict['permutation_importance'].split(',')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.121764e-01</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>5.393023e-04</td>\n",
       "      <td>0.015026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.017604</td>\n",
       "      <td>0.497937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.716807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.716807</td>\n",
       "      <td>0.716807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.100000e-06</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.952333e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3.581395e-06</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.452895e-01</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>1.381395e-05</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.023197</td>\n",
       "      <td>0.008753</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.448739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448739</td>\n",
       "      <td>0.448739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.053253e-01</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>5.398605e-04</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.753095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.305042</td>\n",
       "      <td>0.586006</td>\n",
       "      <td>0.543697</td>\n",
       "      <td>0.065990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>1.128042e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>6.651163e-06</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>4.416667e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.790698e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>4.665850e-03</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5.398605e-04</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.494756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>7.134503e-01</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>5.393023e-04</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.017216</td>\n",
       "      <td>0.746905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.710924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710924</td>\n",
       "      <td>0.710924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>4.788605e-02</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0      7.121764e-01           0.001010                0.000607   \n",
       "1      1.100000e-06           0.000144                0.000000   \n",
       "2      1.952333e-04           0.000000                0.000101   \n",
       "3      4.452895e-01           0.000144                0.000202   \n",
       "4      6.053253e-01           0.001010                0.000506   \n",
       "...             ...                ...                     ...   \n",
       "3995   1.128042e-03           0.000000                0.000101   \n",
       "3996   4.416667e-07           0.000000                0.000101   \n",
       "3997   4.665850e-03           0.000289                0.000607   \n",
       "3998   7.134503e-01           0.000866                0.000709   \n",
       "3999   4.788605e-02           0.000289                0.000101   \n",
       "\n",
       "      Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                        0.000122                 5.393023e-04   \n",
       "1                        0.000013                 0.000000e+00   \n",
       "2                        0.000016                 3.581395e-06   \n",
       "3                        0.000036                 1.381395e-05   \n",
       "4                        0.000020                 5.398605e-04   \n",
       "...                           ...                          ...   \n",
       "3995                     0.000016                 6.651163e-06   \n",
       "3996                     0.000000                 2.790698e-07   \n",
       "3997                     0.000009                 5.398605e-04   \n",
       "3998                     0.000119                 5.393023e-04   \n",
       "3999                     0.000000                 0.000000e+00   \n",
       "\n",
       "      Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                  0.015026               0.000000                0.007385   \n",
       "1                  0.001584               0.000000                0.003114   \n",
       "2                  0.001926               0.022693                0.007575   \n",
       "3                  0.002483               0.023197                0.008753   \n",
       "4                  0.000856               0.000000                0.001178   \n",
       "...                     ...                    ...                     ...   \n",
       "3995               0.001926               0.022693                0.007575   \n",
       "3996               0.000000               0.000000                0.000000   \n",
       "3997               0.000856               0.000000                0.001459   \n",
       "3998               0.013870               0.000000                0.008224   \n",
       "3999               0.000000               0.000000                0.000000   \n",
       "\n",
       "      Fwd Packet Length Std  Bwd Packet Length Max  ...  act_data_pkt_fwd  \\\n",
       "0                  0.017604               0.497937  ...          0.000167   \n",
       "1                  0.003711               0.000000  ...          0.000000   \n",
       "2                  0.000000               0.006620  ...          0.000000   \n",
       "3                  0.001204               0.015990  ...          0.000167   \n",
       "4                  0.000802               0.753095  ...          0.001001   \n",
       "...                     ...                    ...  ...               ...   \n",
       "3995               0.000000               0.012294  ...          0.000000   \n",
       "3996               0.000000               0.000516  ...          0.000000   \n",
       "3997               0.001456               0.494756  ...          0.000334   \n",
       "3998               0.017216               0.746905  ...          0.000501   \n",
       "3999               0.000000               0.000000  ...          0.000000   \n",
       "\n",
       "      min_seg_size_forward  Active Mean  Active Std  Active Max  Active Min  \\\n",
       "0                 0.533333     0.000020         0.0    0.000020    0.000020   \n",
       "1                 0.533333     0.000000         0.0    0.000000    0.000000   \n",
       "2                 0.533333     0.000000         0.0    0.000000    0.000000   \n",
       "3                 0.533333     0.000307         0.0    0.000307    0.000307   \n",
       "4                 0.333333     0.000010         0.0    0.000010    0.000010   \n",
       "...                    ...          ...         ...         ...         ...   \n",
       "3995              0.533333     0.000000         0.0    0.000000    0.000000   \n",
       "3996              0.666667     0.000000         0.0    0.000000    0.000000   \n",
       "3997              0.333333     0.000000         0.0    0.000000    0.000000   \n",
       "3998              0.333333     0.000109         0.0    0.000109    0.000109   \n",
       "3999              0.533333     0.000000         0.0    0.000000    0.000000   \n",
       "\n",
       "      Idle Mean  Idle Std  Idle Max  Idle Min  \n",
       "0      0.716807  0.000000  0.716807  0.716807  \n",
       "1      0.000000  0.000000  0.000000  0.000000  \n",
       "2      0.000000  0.000000  0.000000  0.000000  \n",
       "3      0.448739  0.000000  0.448739  0.448739  \n",
       "4      0.305042  0.586006  0.543697  0.065990  \n",
       "...         ...       ...       ...       ...  \n",
       "3995   0.000000  0.000000  0.000000  0.000000  \n",
       "3996   0.000000  0.000000  0.000000  0.000000  \n",
       "3997   0.000000  0.000000  0.000000  0.000000  \n",
       "3998   0.710924  0.000000  0.710924  0.710924  \n",
       "3999   0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[4000 rows x 65 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_variance_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label column to every df\n",
    "\n",
    "df_features_dict={\n",
    "    \"df_variance_threshold\":df_variance_threshold,\n",
    "    \"df_lasso\":df_lasso,\n",
    "    \"df_random_forest_feature_importance\":df_random_forest_feature_importance,\n",
    "    \"df_permutation_importance\":df_permutation_importance,\n",
    "}\n",
    "\n",
    "for df_feature in df_features_dict.keys():\n",
    "    df_features_dict[df_feature]['Label'] = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running LGB classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # LGB classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('lgbm', lgb.LGBMClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'lgbm__n_estimators': [50, 100, 200],\n",
    "        'lgbm__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'lgbm__max_depth': [3, 5, 7]\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    lgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Adaboost classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Adaboost\n",
    "    pipeline = Pipeline([\n",
    "        ('adaboost', AdaBoostClassifier())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'adaboost__n_estimators': [50, 100, 200],\n",
    "        'adaboost__learning_rate': [0.01, 0.1, 0.2],\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    ada_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "    # Logistic\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Logistic classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('logreg', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'logreg__C': [0.001, 0.01, 0.1],\n",
    "        'logreg__penalty': ['l1', 'l2'],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    logistic_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Naive bayes classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #Naive bayes\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('nb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'nb__alpha': [0.1, 0.5, 1.0]\n",
    "    }\n",
    "\n",
    "    # Create GridSearchCV\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and their corresponding accuracy\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    naivebayes_classifier = grid_search.best_estimator_\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running XGB classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('xgb', xgb.XGBClassifier())\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'xgb__n_estimators': [50, 100],\n",
    "        'xgb__learning_rate': [0.01, 0.1],\n",
    "        'xgb__max_depth': [3, 5]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "    test_accuracy = grid_search.score(X_test, y_test)\n",
    "    print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "    xgb_classifier = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"Running Stacking based classifier\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Stacking\n",
    "    base_models = [\n",
    "        ('xgboost', xgb_classifier),\n",
    "        ('lightgbm', lgb_classifier),\n",
    "        ('adaboost', ada_classifier),\n",
    "        ('logistic', logistic_classifier),\n",
    "        ('naive_bayes', naivebayes_classifier)\n",
    "    ]\n",
    "    meta_model = LogisticRegression()\n",
    "    stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "    stacking_classifier.fit(X_train, y_train)\n",
    "    y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "    stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "    print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9896875000000002\n",
      "Test Accuracy: 0.98125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.60125\n",
      "Test Accuracy: 0.62875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.776875\n",
      "Test Accuracy: 0.825\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.74\n",
      "Test Accuracy: 0.76\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9890625\n",
      "Test Accuracy: 0.99125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.9825\n"
     ]
    }
   ],
   "source": [
    "X=df_variance_threshold.drop('Label',axis=1)\n",
    "y=df_variance_threshold['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9893750000000001\n",
      "Test Accuracy: 0.98125\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.01, 'adaboost__n_estimators': 50}\n",
      "Best Accuracy: 0.60125\n",
      "Test Accuracy: 0.62875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.6496875000000001\n",
      "Test Accuracy: 0.6525\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.566875\n",
      "Test Accuracy: 0.5975\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9890625\n",
      "Test Accuracy: 0.9875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.9875\n"
     ]
    }
   ],
   "source": [
    "X=df_permutation_importance.drop('Label',axis=1)\n",
    "y=df_permutation_importance['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_random_forest_feature_importance.drop('Label',axis=1)\n",
    "y=df_random_forest_feature_importance['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on multiclass labels\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.01, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.8521875\n",
      "Test Accuracy: 0.855\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.6915625000000001\n",
      "Test Accuracy: 0.7175\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.60375\n",
      "Test Accuracy: 0.60625\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.54\n",
      "Test Accuracy: 0.56875\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.8543749999999999\n",
      "Test Accuracy: 0.86\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.86125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Model running on multiclass labels\")\n",
    "\n",
    "X=df_lasso.drop('Label',axis=1)\n",
    "y=df_lasso['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TWO labels Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/final_data_two_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiter = \"------------------\"\n",
    "with open(\"./data/features_with_two_labels.txt\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "features_dict = {}\n",
    "for line in lines[1:]:\n",
    "    line = line.strip()\n",
    "    splited_lines = line.split(delimiter)\n",
    "    features_dict[splited_lines[0]]=splited_lines[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance_threshold_two = df[[x for x in features_dict['variance_threshold'].split(',')]]\n",
    "df_random_forest_feature_importance_two = df[[x for x in features_dict['random_forest_feature_importance'].split(',')]]\n",
    "df_recursive_feature_elimination_two = df[[x for x in features_dict['recursive_feature_elimination'].split(',')]]\n",
    "df_permutation_importance_two = df[[x for x in features_dict['permutation_importance'].split(',')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_dict={\n",
    "    \"df_variance_threshold\":df_variance_threshold_two,\n",
    "    \"df_random_forest_feature_importance\":df_random_forest_feature_importance_two,\n",
    "    \"df_permutation_importance\":df_permutation_importance_two,\n",
    "    \"recursive_feature_elimination\":df_recursive_feature_elimination_two\n",
    "}\n",
    "\n",
    "for df_feature in df_features_dict.keys():\n",
    "    df_features_dict[df_feature]['Label'] = df['Label']\n",
    "\n",
    "    df_recursive_feature_elimination_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9896666666666667\n",
      "Test Accuracy: 0.991\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9650000000000001\n",
      "Test Accuracy: 0.973\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.825\n",
      "Test Accuracy: 0.858\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.5853333333333334\n",
      "Test Accuracy: 0.627\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9863333333333333\n",
      "Test Accuracy: 0.988\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.992\n"
     ]
    }
   ],
   "source": [
    "X=df_variance_threshold_two.drop('Label',axis=1)\n",
    "y=df_variance_threshold_two['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9873333333333333\n",
      "Test Accuracy: 0.985\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9536666666666666\n",
      "Test Accuracy: 0.956\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.669\n",
      "Test Accuracy: 0.686\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.7023333333333334\n",
      "Test Accuracy: 0.714\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.982\n",
      "Test Accuracy: 0.987\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.986\n"
     ]
    }
   ],
   "source": [
    "X=df_random_forest_feature_importance_two.drop('Label',axis=1)\n",
    "y=df_random_forest_feature_importance_two['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.2, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9873333333333333\n",
      "Test Accuracy: 0.987\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9523333333333334\n",
      "Test Accuracy: 0.957\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.667\n",
      "Test Accuracy: 0.686\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.6913333333333334\n",
      "Test Accuracy: 0.729\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9823333333333333\n",
      "Test Accuracy: 0.984\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.987\n"
     ]
    }
   ],
   "source": [
    "X=df_recursive_feature_elimination_two.drop('Label',axis=1)\n",
    "y=df_recursive_feature_elimination_two['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': 5, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.9906666666666666\n",
      "Test Accuracy: 0.99\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9526666666666668\n",
      "Test Accuracy: 0.966\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.8013333333333333\n",
      "Test Accuracy: 0.822\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 0.1}\n",
      "Best Accuracy: 0.4576666666666666\n",
      "Test Accuracy: 0.486\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.9876666666666667\n",
      "Test Accuracy: 0.987\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.991\n"
     ]
    }
   ],
   "source": [
    "X=df_permutation_importance_two.drop('Label',axis=1)\n",
    "y=df_permutation_importance_two['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in features_dict.items():\n",
    "    if key=='lasso' or key=='variance_threshold':\n",
    "        continue\n",
    "    subset_feature_dict[key]=item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on two labels\n"
     ]
    }
   ],
   "source": [
    "# TODO separate into columns\n",
    "print(\"Model running on two labels\")\n",
    "X = df.drop(\"Label\", axis=1)\n",
    "y = df[\"Label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 0.99\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('xgboost', xgb.XGBClassifier()),\n",
    "    ('lightgbm', lgb.LGBMClassifier()),\n",
    "    ('adaboost', AdaBoostClassifier()),\n",
    "    ('logistic', LogisticRegression()),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 18, got 77",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/gauravadhikari/CourseWorks/fall2023/security/security-project/algo_implement.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gauravadhikari/CourseWorks/fall2023/security/security-project/algo_implement.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred \u001b[39m=\u001b[39m stacking_classifier\u001b[39m.\u001b[39;49mpredict(df\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mLabel\u001b[39;49m\u001b[39m'\u001b[39;49m,axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gauravadhikari/CourseWorks/fall2023/security/security-project/algo_implement.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m incorrect_twolabel_idx \u001b[39m=\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m y_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gauravadhikari/CourseWorks/fall2023/security/security-project/algo_implement.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# incorrect_predicted_df = df[incorrect_twolabel_idx]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:683\u001b[0m, in \u001b[0;36mStackingClassifier.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[39m@available_if\u001b[39m(_estimator_has(\u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    663\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params):\n\u001b[1;32m    664\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \n\u001b[1;32m    666\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[39m        Predicted targets.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 683\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpredict_params)\n\u001b[1;32m    684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_encoder, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    685\u001b[0m         \u001b[39m# Handle the multilabel-indicator case\u001b[39;00m\n\u001b[1;32m    686\u001b[0m         y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[1;32m    687\u001b[0m             [\n\u001b[1;32m    688\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_encoder[target_idx]\u001b[39m.\u001b[39minverse_transform(target)\n\u001b[1;32m    689\u001b[0m                 \u001b[39mfor\u001b[39;00m target_idx, target \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(y_pred\u001b[39m.\u001b[39mT)\n\u001b[1;32m    690\u001b[0m             ]\n\u001b[1;32m    691\u001b[0m         )\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:371\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39m    Predicted targets.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 371\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_estimator_\u001b[39m.\u001b[39mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(X), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:754\u001b[0m, in \u001b[0;36mStackingClassifier.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    740\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return class labels or probabilities for X for each estimator.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39m        Prediction outputs for each estimator.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:296\u001b[0m, in \u001b[0;36m_BaseStacking._transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 296\u001b[0m predictions \u001b[39m=\u001b[39m [\n\u001b[1;32m    297\u001b[0m     \u001b[39mgetattr\u001b[39;49m(est, meth)(X)\n\u001b[1;32m    298\u001b[0m     \u001b[39mfor\u001b[39;49;00m est, meth \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_method_)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;49;00m est \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdrop\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    300\u001b[0m ]\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:297\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    296\u001b[0m predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mgetattr\u001b[39;49m(est, meth)(X)\n\u001b[1;32m    298\u001b[0m     \u001b[39mfor\u001b[39;00m est, meth \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_method_)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m est \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m ]\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/xgboost/sklearn.py:1606\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[0;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1604\u001b[0m     class_prob \u001b[39m=\u001b[39m softmax(raw_predt, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m   1605\u001b[0m     \u001b[39mreturn\u001b[39;00m class_prob\n\u001b[0;32m-> 1606\u001b[0m class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m   1607\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1608\u001b[0m     ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[1;32m   1609\u001b[0m     validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1610\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1611\u001b[0m     iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m   1612\u001b[0m )\n\u001b[1;32m   1613\u001b[0m \u001b[39m# If model is loaded from a raw booster there's no `n_classes_`\u001b[39;00m\n\u001b[1;32m   1614\u001b[0m \u001b[39mreturn\u001b[39;00m _cls_predict_proba(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_classes_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m), class_probs, np\u001b[39m.\u001b[39mvstack\n\u001b[1;32m   1616\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/xgboost/sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1113\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1114\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[1;32m   1115\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1116\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m   1117\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1118\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1119\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1120\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1121\u001b[0m         )\n\u001b[1;32m   1122\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m   1123\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/xgboost/core.py:2268\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2265\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2266\u001b[0m         )\n\u001b[1;32m   2267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features() \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m-> 2268\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2269\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape mismatch, expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2270\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2271\u001b[0m         )\n\u001b[1;32m   2273\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m   2274\u001b[0m     _array_interface,\n\u001b[1;32m   2275\u001b[0m     _is_cudf_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     _transform_pandas_df,\n\u001b[1;32m   2279\u001b[0m )\n\u001b[1;32m   2281\u001b[0m enable_categorical \u001b[39m=\u001b[39m _has_categorical(\u001b[39mself\u001b[39m, data)\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 18, got 77"
     ]
    }
   ],
   "source": [
    "# y_pred = stacking_classifier.predict(df.drop('Label',axis=1))\n",
    "# incorrect_twolabel_idx = (df['Label'] != y_pred)\n",
    "# incorrect_predicted_df = df[incorrect_twolabel_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso': 'Fwd IAT Max,PSH Flag Count,ACK Flag Count',\n",
       " 'random_forest_feature_importance': 'Init_Win_bytes_forward,Init_Win_bytes_backward,Min Packet Length,Packet Length Std,Fwd Packet Length Min,Avg Bwd Segment Size,Bwd Packet Length Min,Bwd Packet Length Mean,Fwd Packet Length Max,Packet Length Mean,Packet Length Variance,Total Length of Fwd Packets,Bwd Packet Length Max,Fwd Header Length,Avg Fwd Segment Size,Average Packet Size,Max Packet Length,Bwd Packet Length Std',\n",
       " 'recursive_feature_elimination': 'Total Length of Fwd Packets,Fwd Packet Length Max,Fwd Packet Length Mean,Bwd Packet Length Min,Bwd Packet Length Mean,Bwd Packet Length Std,Fwd Header Length,Min Packet Length,Max Packet Length,Packet Length Mean,Packet Length Std,Packet Length Variance,Average Packet Size,Avg Bwd Segment Size,Fwd Header Length.1,Subflow Fwd Bytes,Init_Win_bytes_forward,Init_Win_bytes_backward',\n",
       " 'permutation_importance': 'Init_Win_bytes_forward,Init_Win_bytes_backward,Fwd IAT Min,PSH Flag Count,Bwd Packet Length Max,Packet Length Variance,Fwd PSH Flags,Total Length of Fwd Packets,ACK Flag Count,min_seg_size_forward,Max Packet Length,Bwd Packet Length Std,Packet Length Mean,Flow IAT Min,Bwd Packet Length Mean,Packet Length Std,Idle Min,Idle Mean'}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bwd Packet Length Mean', 'Packet Length Std', 'PSH Flag Count', 'Packet Length Variance', 'Init_Win_bytes_backward', 'Fwd IAT Max', 'ACK Flag Count', 'Bwd Packet Length Std', 'Max Packet Length', 'Init_Win_bytes_forward', 'Total Length of Fwd Packets', 'Packet Length Mean']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "imp1 = set([x for x in subset_feature_dict['random_forest_feature_importance'].split(',') if x ])\n",
    "imp2 = set([x for x in subset_feature_dict['recursive_feature_elimination'].split(',') if x ])\n",
    "imp3 = set([x for x in subset_feature_dict['permutation_importance'].split(',') if x ])\n",
    "imp4 = set([x for x in subset_feature_dict['lasso'].split(',') if x ])\n",
    "\n",
    "\n",
    "# for key in subset_feature_dict.keys():\n",
    "#     if key != \"random_forest_feature_importance\" or \"lasso\":\n",
    "#         # b = set([x for x in subset_feature_dict[key].split(',') if x])\n",
    "#         seta = temp_lis.union(set.intersection(seta,set([x for x in subset_feature_dict[key].split(',') if x])))\n",
    "\n",
    "\n",
    "finalset = imp1.intersection(imp2).intersection(imp3)\n",
    "finalset=list(finalset.union(imp4))\n",
    "print(finalset)\n",
    "print(len(finalset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twolabel= pd.read_csv(\"./data/final_data_two_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_twolabel[finalset]\n",
    "y=df_twolabel['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running LGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'lgbm__learning_rate': 0.2, 'lgbm__max_depth': 7, 'lgbm__n_estimators': 200}\n",
      "Best Accuracy: 0.986\n",
      "Test Accuracy: 0.985\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Adaboost classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'adaboost__learning_rate': 0.2, 'adaboost__n_estimators': 200}\n",
      "Best Accuracy: 0.9443333333333334\n",
      "Test Accuracy: 0.961\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Logistic classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'logreg__C': 0.1, 'logreg__penalty': 'l2'}\n",
      "Best Accuracy: 0.7933333333333333\n",
      "Test Accuracy: 0.817\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Naive bayes classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'nb__alpha': 1.0}\n",
      "Best Accuracy: 0.4716666666666667\n",
      "Test Accuracy: 0.487\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running XGB classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 5, 'xgb__n_estimators': 100}\n",
      "Best Accuracy: 0.983\n",
      "Test Accuracy: 0.982\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "Running Stacking based classifier\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Accuracy of Stacking Classifier: 0.987\n"
     ]
    }
   ],
   "source": [
    "train_classifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 0.989\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('xgboost', xgb.XGBClassifier()),\n",
    "    ('lightgbm', lgb.LGBMClassifier()),\n",
    "    ('adaboost', AdaBoostClassifier()),\n",
    "    ('logistic', LogisticRegression()),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = stacking_classifier.predict(X_test)\n",
    "incorrect_twolabel_idx = (df_twolabel['Label'] != y_pred)\n",
    "\n",
    "df_exclude_from_pca = X[incorrect_twolabel_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exclude_from_pca['Label']=y[incorrect_twolabel_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bwd Packet Length Mean</th>\n",
       "      <th>Packet Length Std</th>\n",
       "      <th>PSH Flag Count</th>\n",
       "      <th>Packet Length Variance</th>\n",
       "      <th>Init_Win_bytes_backward</th>\n",
       "      <th>Fwd IAT Max</th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>Bwd Packet Length Std</th>\n",
       "      <th>Max Packet Length</th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Packet Length Mean</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.061279e-05</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.445572</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.006480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.405405e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.031311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.904338e-02</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084889</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.640333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>0.146485</td>\n",
       "      <td>0.168647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.840912e-02</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169321</td>\n",
       "      <td>0.097046</td>\n",
       "      <td>0.445572</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.163232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bwd Packet Length Mean  Packet Length Std  PSH Flag Count  \\\n",
       "543                 0.004588           0.003260             1.0   \n",
       "605                 0.000000           0.000000             0.0   \n",
       "1146                0.001551           0.000736             1.0   \n",
       "1876                0.001551           0.000000             0.0   \n",
       "2464                0.000000           0.000000             0.0   \n",
       "2584                0.001551           0.000000             0.0   \n",
       "2665                0.000000           0.243128             0.0   \n",
       "3201                0.146485           0.168647             1.0   \n",
       "3265                0.001551           0.000000             0.0   \n",
       "3284                0.001551           0.000000             0.0   \n",
       "\n",
       "      Packet Length Variance  Init_Win_bytes_backward  Fwd IAT Max  \\\n",
       "543             1.061279e-05                 0.003479     0.001034   \n",
       "605             0.000000e+00                 0.003754     0.000000   \n",
       "1146            5.405405e-07                 0.000015     0.000000   \n",
       "1876            0.000000e+00                 0.031311     0.000000   \n",
       "2464            0.000000e+00                 0.000000     0.000002   \n",
       "2584            0.000000e+00                 0.005127     0.000000   \n",
       "2665            5.904338e-02                 0.003601     0.000000   \n",
       "3201            2.840912e-02                 0.003601     0.008554   \n",
       "3265            0.000000e+00                 0.003830     0.000000   \n",
       "3284            0.000000e+00                 0.003906     0.000000   \n",
       "\n",
       "      ACK Flag Count  Bwd Packet Length Std  Max Packet Length  \\\n",
       "543              0.0               0.002463           0.002226   \n",
       "605              1.0               0.000000           0.000000   \n",
       "1146             0.0               0.000000           0.000257   \n",
       "1876             1.0               0.000000           0.000257   \n",
       "2464             1.0               0.000000           0.000257   \n",
       "2584             1.0               0.000000           0.000257   \n",
       "2665             1.0               0.000000           0.084889   \n",
       "3201             0.0               0.169321           0.097046   \n",
       "3265             1.0               0.000000           0.000257   \n",
       "3284             1.0               0.000000           0.000257   \n",
       "\n",
       "      Init_Win_bytes_forward  Total Length of Fwd Packets  Packet Length Mean  \\\n",
       "543                 0.445572                     0.000061            0.006480   \n",
       "605                 0.003830                     0.000000            0.000000   \n",
       "1146                1.000000                     0.000000            0.000969   \n",
       "1876                0.003891                     0.000002            0.002906   \n",
       "2464                0.003876                     0.000004            0.002906   \n",
       "2584                0.003952                     0.000002            0.002906   \n",
       "2665                0.003601                     0.000692            0.640333   \n",
       "3201                0.445572                     0.000150            0.163232   \n",
       "3265                0.003754                     0.000002            0.002906   \n",
       "3284                0.003632                     0.000002            0.002906   \n",
       "\n",
       "      Label  \n",
       "543       1  \n",
       "605       1  \n",
       "1146      1  \n",
       "1876      1  \n",
       "2464      0  \n",
       "2584      1  \n",
       "2665      0  \n",
       "3201      1  \n",
       "3265      1  \n",
       "3284      1  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exclude_from_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA WITH ZISHAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.read_csv('./data/sample_pca_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 19)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3608\n",
       "1     392\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>-0.699280</td>\n",
       "      <td>0.536016</td>\n",
       "      <td>0.099406</td>\n",
       "      <td>0.296172</td>\n",
       "      <td>-0.030088</td>\n",
       "      <td>-0.043975</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>-0.142628</td>\n",
       "      <td>0.078807</td>\n",
       "      <td>0.012070</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>-0.082427</td>\n",
       "      <td>-0.018856</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>-0.033516</td>\n",
       "      <td>0.027057</td>\n",
       "      <td>-0.022204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>-0.326403</td>\n",
       "      <td>-0.960372</td>\n",
       "      <td>-0.196894</td>\n",
       "      <td>0.045892</td>\n",
       "      <td>-0.502529</td>\n",
       "      <td>0.578415</td>\n",
       "      <td>0.222577</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>-0.060615</td>\n",
       "      <td>-0.023221</td>\n",
       "      <td>-0.010280</td>\n",
       "      <td>-0.016808</td>\n",
       "      <td>-0.029140</td>\n",
       "      <td>-0.005123</td>\n",
       "      <td>0.032271</td>\n",
       "      <td>-0.084165</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>-0.742576</td>\n",
       "      <td>0.618895</td>\n",
       "      <td>0.096048</td>\n",
       "      <td>0.475762</td>\n",
       "      <td>-0.029228</td>\n",
       "      <td>-0.024974</td>\n",
       "      <td>-0.010756</td>\n",
       "      <td>-0.324608</td>\n",
       "      <td>0.588025</td>\n",
       "      <td>0.061011</td>\n",
       "      <td>0.036499</td>\n",
       "      <td>-0.002365</td>\n",
       "      <td>-0.151749</td>\n",
       "      <td>-0.007891</td>\n",
       "      <td>0.035590</td>\n",
       "      <td>-0.052594</td>\n",
       "      <td>0.060702</td>\n",
       "      <td>-0.038425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>-0.325169</td>\n",
       "      <td>-0.959099</td>\n",
       "      <td>-0.199298</td>\n",
       "      <td>0.045988</td>\n",
       "      <td>-0.502822</td>\n",
       "      <td>0.579819</td>\n",
       "      <td>0.221138</td>\n",
       "      <td>0.012802</td>\n",
       "      <td>-0.058163</td>\n",
       "      <td>-0.026946</td>\n",
       "      <td>-0.006538</td>\n",
       "      <td>-0.014236</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.026520</td>\n",
       "      <td>-0.080460</td>\n",
       "      <td>0.034919</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>-0.297795</td>\n",
       "      <td>-0.794256</td>\n",
       "      <td>-0.118694</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>-0.004530</td>\n",
       "      <td>-0.079659</td>\n",
       "      <td>-0.287630</td>\n",
       "      <td>0.017805</td>\n",
       "      <td>-0.062198</td>\n",
       "      <td>-0.008251</td>\n",
       "      <td>-0.200533</td>\n",
       "      <td>-0.032424</td>\n",
       "      <td>-0.019212</td>\n",
       "      <td>-0.009085</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>-0.023946</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>-0.299788</td>\n",
       "      <td>-0.788474</td>\n",
       "      <td>-0.118841</td>\n",
       "      <td>-0.006989</td>\n",
       "      <td>-0.015315</td>\n",
       "      <td>-0.067762</td>\n",
       "      <td>-0.265721</td>\n",
       "      <td>0.022541</td>\n",
       "      <td>-0.065481</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>-0.191929</td>\n",
       "      <td>-0.036803</td>\n",
       "      <td>-0.043544</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.008305</td>\n",
       "      <td>-0.018841</td>\n",
       "      <td>-0.017912</td>\n",
       "      <td>-0.050077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>-0.032323</td>\n",
       "      <td>-0.715937</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.121761</td>\n",
       "      <td>1.282308</td>\n",
       "      <td>0.451636</td>\n",
       "      <td>0.256235</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>-0.003730</td>\n",
       "      <td>0.250798</td>\n",
       "      <td>0.089385</td>\n",
       "      <td>-0.141799</td>\n",
       "      <td>-0.086782</td>\n",
       "      <td>0.767500</td>\n",
       "      <td>-0.117314</td>\n",
       "      <td>0.415653</td>\n",
       "      <td>0.079065</td>\n",
       "      <td>-0.025331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>-0.480385</td>\n",
       "      <td>0.691755</td>\n",
       "      <td>-0.190966</td>\n",
       "      <td>0.143876</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>0.024129</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>-0.108111</td>\n",
       "      <td>0.125467</td>\n",
       "      <td>0.038387</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>-0.065764</td>\n",
       "      <td>-0.009786</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>-0.000806</td>\n",
       "      <td>0.034421</td>\n",
       "      <td>-0.014888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>-0.327387</td>\n",
       "      <td>-0.954122</td>\n",
       "      <td>-0.198746</td>\n",
       "      <td>0.032571</td>\n",
       "      <td>-0.512440</td>\n",
       "      <td>0.590624</td>\n",
       "      <td>0.242851</td>\n",
       "      <td>0.020329</td>\n",
       "      <td>-0.065137</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>-0.021279</td>\n",
       "      <td>-0.056913</td>\n",
       "      <td>0.012066</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>-0.079921</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>-0.044888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>-0.324859</td>\n",
       "      <td>-0.959767</td>\n",
       "      <td>-0.199639</td>\n",
       "      <td>0.044136</td>\n",
       "      <td>-0.501331</td>\n",
       "      <td>0.578815</td>\n",
       "      <td>0.219280</td>\n",
       "      <td>0.014722</td>\n",
       "      <td>-0.061912</td>\n",
       "      <td>-0.020214</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>-0.015487</td>\n",
       "      <td>-0.026703</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.032442</td>\n",
       "      <td>-0.086213</td>\n",
       "      <td>0.041209</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "543  -0.699280  0.536016  0.099406  0.296172 -0.030088 -0.043975  0.026154   \n",
       "605  -0.326403 -0.960372 -0.196894  0.045892 -0.502529  0.578415  0.222577   \n",
       "1146 -0.742576  0.618895  0.096048  0.475762 -0.029228 -0.024974 -0.010756   \n",
       "1876 -0.325169 -0.959099 -0.199298  0.045988 -0.502822  0.579819  0.221138   \n",
       "2464 -0.297795 -0.794256 -0.118694  0.004892 -0.004530 -0.079659 -0.287630   \n",
       "2584 -0.299788 -0.788474 -0.118841 -0.006989 -0.015315 -0.067762 -0.265721   \n",
       "2665 -0.032323 -0.715937 -0.606624 -0.121761  1.282308  0.451636  0.256235   \n",
       "3201 -0.480385  0.691755 -0.190966  0.143876 -0.000306  0.024129 -0.002778   \n",
       "3265 -0.327387 -0.954122 -0.198746  0.032571 -0.512440  0.590624  0.242851   \n",
       "3284 -0.324859 -0.959767 -0.199639  0.044136 -0.501331  0.578815  0.219280   \n",
       "\n",
       "             7         8         9        10        11        12        13  \\\n",
       "543  -0.142628  0.078807  0.012070 -0.007546  0.006533 -0.082427 -0.018856   \n",
       "605   0.015269 -0.060615 -0.023221 -0.010280 -0.016808 -0.029140 -0.005123   \n",
       "1146 -0.324608  0.588025  0.061011  0.036499 -0.002365 -0.151749 -0.007891   \n",
       "1876  0.012802 -0.058163 -0.026946 -0.006538 -0.014236 -0.004334  0.003987   \n",
       "2464  0.017805 -0.062198 -0.008251 -0.200533 -0.032424 -0.019212 -0.009085   \n",
       "2584  0.022541 -0.065481  0.012513 -0.191929 -0.036803 -0.043544  0.004380   \n",
       "2665  0.014913 -0.003730  0.250798  0.089385 -0.141799 -0.086782  0.767500   \n",
       "3201 -0.108111  0.125467  0.038387 -0.000717  0.011689 -0.065764 -0.009786   \n",
       "3265  0.020329 -0.065137  0.000528  0.003990 -0.021279 -0.056913  0.012066   \n",
       "3284  0.014722 -0.061912 -0.020214  0.000925 -0.015487 -0.026703  0.000940   \n",
       "\n",
       "            14        15        16        17  Label  \n",
       "543   0.014345 -0.033516  0.027057 -0.022204      0  \n",
       "605   0.032271 -0.084165  0.041195  0.004150      0  \n",
       "1146  0.035590 -0.052594  0.060702 -0.038425      0  \n",
       "1876  0.026520 -0.080460  0.034919  0.003708      0  \n",
       "2464  0.009743 -0.023946  0.011255 -0.000897      0  \n",
       "2584  0.008305 -0.018841 -0.017912 -0.050077      0  \n",
       "2665 -0.117314  0.415653  0.079065 -0.025331      0  \n",
       "3201  0.012102 -0.000806  0.034421 -0.014888      0  \n",
       "3265  0.031859 -0.079921  0.013561 -0.044888      0  \n",
       "3284  0.032442 -0.086213  0.041209  0.004328      0  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df[incorrect_twolabel_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.143753</td>\n",
       "      <td>-0.782227</td>\n",
       "      <td>-0.055468</td>\n",
       "      <td>0.065188</td>\n",
       "      <td>-0.018130</td>\n",
       "      <td>-0.113716</td>\n",
       "      <td>-0.243861</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>-0.073843</td>\n",
       "      <td>-0.011362</td>\n",
       "      <td>-0.193028</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>-0.018387</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>-0.029356</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>-0.007800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.331393</td>\n",
       "      <td>-0.883429</td>\n",
       "      <td>-0.174530</td>\n",
       "      <td>0.279142</td>\n",
       "      <td>1.201023</td>\n",
       "      <td>0.336282</td>\n",
       "      <td>0.245202</td>\n",
       "      <td>-0.177226</td>\n",
       "      <td>0.296793</td>\n",
       "      <td>-0.062374</td>\n",
       "      <td>-0.161110</td>\n",
       "      <td>-0.047008</td>\n",
       "      <td>-0.029037</td>\n",
       "      <td>0.054116</td>\n",
       "      <td>0.040903</td>\n",
       "      <td>-0.198770</td>\n",
       "      <td>0.125681</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.470115</td>\n",
       "      <td>-0.155329</td>\n",
       "      <td>0.254311</td>\n",
       "      <td>-0.425293</td>\n",
       "      <td>-0.012344</td>\n",
       "      <td>-0.217913</td>\n",
       "      <td>0.135217</td>\n",
       "      <td>0.105302</td>\n",
       "      <td>0.099356</td>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.038704</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>-0.004991</td>\n",
       "      <td>-0.034499</td>\n",
       "      <td>-0.037582</td>\n",
       "      <td>0.044955</td>\n",
       "      <td>-0.011845</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.109564</td>\n",
       "      <td>0.625984</td>\n",
       "      <td>0.458123</td>\n",
       "      <td>0.411551</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.122121</td>\n",
       "      <td>0.466561</td>\n",
       "      <td>-0.144026</td>\n",
       "      <td>-0.097631</td>\n",
       "      <td>0.037290</td>\n",
       "      <td>-0.171365</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>-0.062001</td>\n",
       "      <td>0.061098</td>\n",
       "      <td>-0.035839</td>\n",
       "      <td>0.035015</td>\n",
       "      <td>-0.037644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.676691</td>\n",
       "      <td>0.464214</td>\n",
       "      <td>0.111799</td>\n",
       "      <td>0.163930</td>\n",
       "      <td>-0.030680</td>\n",
       "      <td>-0.064653</td>\n",
       "      <td>0.053822</td>\n",
       "      <td>-0.008131</td>\n",
       "      <td>-0.313954</td>\n",
       "      <td>-0.019238</td>\n",
       "      <td>-0.019592</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>-0.033681</td>\n",
       "      <td>-0.035608</td>\n",
       "      <td>-0.003461</td>\n",
       "      <td>-0.011992</td>\n",
       "      <td>-0.003990</td>\n",
       "      <td>-0.009252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.143753 -0.782227 -0.055468  0.065188 -0.018130 -0.113716 -0.243861   \n",
       "1 -0.331393 -0.883429 -0.174530  0.279142  1.201023  0.336282  0.245202   \n",
       "2 -0.470115 -0.155329  0.254311 -0.425293 -0.012344 -0.217913  0.135217   \n",
       "3 -0.109564  0.625984  0.458123  0.411551  0.008078  0.175520 -0.122121   \n",
       "4 -0.676691  0.464214  0.111799  0.163930 -0.030680 -0.064653  0.053822   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  0.006122 -0.073843 -0.011362 -0.193028 -0.032397 -0.018387 -0.002426   \n",
       "1 -0.177226  0.296793 -0.062374 -0.161110 -0.047008 -0.029037  0.054116   \n",
       "2  0.105302  0.099356  0.032333  0.038704  0.006909 -0.004991 -0.034499   \n",
       "3  0.466561 -0.144026 -0.097631  0.037290 -0.171365  0.008826 -0.062001   \n",
       "4 -0.008131 -0.313954 -0.019238 -0.019592  0.017496 -0.033681 -0.035608   \n",
       "\n",
       "         14        15        16        17  Label  \n",
       "0  0.009735 -0.029356  0.023656 -0.007800      1  \n",
       "1  0.040903 -0.198770  0.125681 -0.001151      1  \n",
       "2 -0.037582  0.044955 -0.011845  0.005155      1  \n",
       "3  0.061098 -0.035839  0.035015 -0.037644      1  \n",
       "4 -0.003461 -0.011992 -0.003990 -0.009252      1  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pca_df.drop('Label', axis=1)\n",
    "y= pca_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Classifier: 0.903\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_models = [\n",
    "    ('xgboost', xgb.XGBClassifier()),\n",
    "    ('lightgbm', lgb.LGBMClassifier()),\n",
    "    ('adaboost', AdaBoostClassifier()),\n",
    "    ('logistic', LogisticRegression()),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "]\n",
    "meta_model = LogisticRegression()\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_predict_stacking = stacking_classifier.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, y_predict_stacking)\n",
    "\n",
    "print('Accuracy of Stacking Classifier: ' + str(stacking_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>Bwd Packet Length Max</th>\n",
       "      <th>...</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1.149592e-03</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>1.981395e-05</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1.491667e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>7.054167e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.790698e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>4.750000e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.790698e-07</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>1.783333e-06</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>8.000000e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.790698e-07</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.084889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>9.037083e-03</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>1.054419e-04</td>\n",
       "      <td>0.018365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024071</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>0.194893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>6.166667e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.581395e-07</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>3.500000e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.790698e-07</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "543    1.149592e-03           0.002742                0.002430   \n",
       "605    1.491667e-06           0.000000                0.000101   \n",
       "1146   7.054167e-04           0.000000                0.000101   \n",
       "1876   4.750000e-07           0.000000                0.000101   \n",
       "2464   1.783333e-06           0.000144                0.000000   \n",
       "2584   8.000000e-07           0.000000                0.000101   \n",
       "2665   2.500000e-08           0.000000                0.000101   \n",
       "3201   9.037083e-03           0.000289                0.000405   \n",
       "3265   6.166667e-07           0.000000                0.000202   \n",
       "3284   3.500000e-07           0.000000                0.000101   \n",
       "\n",
       "      Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "543                      0.000061                 1.981395e-05   \n",
       "605                      0.000000                 0.000000e+00   \n",
       "1146                     0.000000                 2.790698e-07   \n",
       "1876                     0.000002                 2.790698e-07   \n",
       "2464                     0.000004                 0.000000e+00   \n",
       "2584                     0.000002                 2.790698e-07   \n",
       "2665                     0.000692                 0.000000e+00   \n",
       "3201                     0.000150                 1.054419e-04   \n",
       "3265                     0.000002                 5.581395e-07   \n",
       "3284                     0.000002                 2.790698e-07   \n",
       "\n",
       "      Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "543                0.001841               0.000000                0.001481   \n",
       "605                0.000000               0.000000                0.000000   \n",
       "1146               0.000000               0.000000                0.000000   \n",
       "1876               0.000257               0.003026                0.001010   \n",
       "2464               0.000257               0.003026                0.001010   \n",
       "2584               0.000257               0.003026                0.001010   \n",
       "2665               0.084889               1.000000                0.333790   \n",
       "3201               0.018365               0.000000                0.024071   \n",
       "3265               0.000257               0.003026                0.001010   \n",
       "3284               0.000257               0.003026                0.001010   \n",
       "\n",
       "      Fwd Packet Length Std  Bwd Packet Length Max  ...  min_seg_size_forward  \\\n",
       "543                0.001799               0.004470  ...              0.533333   \n",
       "605                0.000000               0.000000  ...              0.333333   \n",
       "1146               0.000000               0.000516  ...              0.733333   \n",
       "1876               0.000000               0.000516  ...              0.333333   \n",
       "2464               0.000000               0.000000  ...              0.333333   \n",
       "2584               0.000000               0.000516  ...              0.333333   \n",
       "2665               0.000000               0.000000  ...              0.533333   \n",
       "3201               0.035135               0.194893  ...              0.533333   \n",
       "3265               0.000000               0.000516  ...              0.333333   \n",
       "3284               0.000000               0.000516  ...              0.333333   \n",
       "\n",
       "      Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
       "543           0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "605           0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "1146          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "1876          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "2464          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "2584          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "2665          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "3201          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "3265          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "3284          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "\n",
       "      Idle Max  Idle Min  Label  \n",
       "543        0.0       0.0      1  \n",
       "605        0.0       0.0      1  \n",
       "1146       0.0       0.0      1  \n",
       "1876       0.0       0.0      1  \n",
       "2464       0.0       0.0      0  \n",
       "2584       0.0       0.0      1  \n",
       "2665       0.0       0.0      0  \n",
       "3201       0.0       0.0      1  \n",
       "3265       0.0       0.0      1  \n",
       "3284       0.0       0.0      1  \n",
       "\n",
       "[10 rows x 78 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 18, got 77",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/gauravadhikari/CourseWorks/fall2023/security/security-project/algo_implement.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gauravadhikari/CourseWorks/fall2023/security/security-project/algo_implement.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stacking_classifier\u001b[39m.\u001b[39;49mpredict(incorrect_predicted_df\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mLabel\u001b[39;49m\u001b[39m'\u001b[39;49m,axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:683\u001b[0m, in \u001b[0;36mStackingClassifier.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[39m@available_if\u001b[39m(_estimator_has(\u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    663\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params):\n\u001b[1;32m    664\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \n\u001b[1;32m    666\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[39m        Predicted targets.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 683\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpredict_params)\n\u001b[1;32m    684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_encoder, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    685\u001b[0m         \u001b[39m# Handle the multilabel-indicator case\u001b[39;00m\n\u001b[1;32m    686\u001b[0m         y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\n\u001b[1;32m    687\u001b[0m             [\n\u001b[1;32m    688\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_encoder[target_idx]\u001b[39m.\u001b[39minverse_transform(target)\n\u001b[1;32m    689\u001b[0m                 \u001b[39mfor\u001b[39;00m target_idx, target \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(y_pred\u001b[39m.\u001b[39mT)\n\u001b[1;32m    690\u001b[0m             ]\n\u001b[1;32m    691\u001b[0m         )\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:371\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39m    Predicted targets.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 371\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_estimator_\u001b[39m.\u001b[39mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(X), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:754\u001b[0m, in \u001b[0;36mStackingClassifier.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    740\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return class labels or probabilities for X for each estimator.\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39m        Prediction outputs for each estimator.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X)\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:296\u001b[0m, in \u001b[0;36m_BaseStacking._transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 296\u001b[0m predictions \u001b[39m=\u001b[39m [\n\u001b[1;32m    297\u001b[0m     \u001b[39mgetattr\u001b[39;49m(est, meth)(X)\n\u001b[1;32m    298\u001b[0m     \u001b[39mfor\u001b[39;49;00m est, meth \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_method_)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;49;00m est \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdrop\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    300\u001b[0m ]\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:297\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    296\u001b[0m predictions \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mgetattr\u001b[39;49m(est, meth)(X)\n\u001b[1;32m    298\u001b[0m     \u001b[39mfor\u001b[39;00m est, meth \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_method_)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m est \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m ]\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concatenate_predictions(X, predictions)\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/xgboost/sklearn.py:1606\u001b[0m, in \u001b[0;36mXGBClassifier.predict_proba\u001b[0;34m(self, X, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1604\u001b[0m     class_prob \u001b[39m=\u001b[39m softmax(raw_predt, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m   1605\u001b[0m     \u001b[39mreturn\u001b[39;00m class_prob\n\u001b[0;32m-> 1606\u001b[0m class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m   1607\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1608\u001b[0m     ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[1;32m   1609\u001b[0m     validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1610\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1611\u001b[0m     iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m   1612\u001b[0m )\n\u001b[1;32m   1613\u001b[0m \u001b[39m# If model is loaded from a raw booster there's no `n_classes_`\u001b[39;00m\n\u001b[1;32m   1614\u001b[0m \u001b[39mreturn\u001b[39;00m _cls_predict_proba(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_classes_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m), class_probs, np\u001b[39m.\u001b[39mvstack\n\u001b[1;32m   1616\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/xgboost/sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1113\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1114\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[1;32m   1115\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1116\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m   1117\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1118\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1119\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1120\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1121\u001b[0m         )\n\u001b[1;32m   1122\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m   1123\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/security/lib/python3.11/site-packages/xgboost/core.py:2268\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2264\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2265\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2266\u001b[0m         )\n\u001b[1;32m   2267\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features() \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m-> 2268\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2269\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape mismatch, expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2270\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2271\u001b[0m         )\n\u001b[1;32m   2273\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m   2274\u001b[0m     _array_interface,\n\u001b[1;32m   2275\u001b[0m     _is_cudf_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2278\u001b[0m     _transform_pandas_df,\n\u001b[1;32m   2279\u001b[0m )\n\u001b[1;32m   2281\u001b[0m enable_categorical \u001b[39m=\u001b[39m _has_categorical(\u001b[39mself\u001b[39m, data)\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 18, got 77"
     ]
    }
   ],
   "source": [
    "stacking_classifier.predict(incorrect_predicted_df.drop('Label',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "security",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
